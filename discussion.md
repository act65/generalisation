## Open questions

> How much of generalisation depends on the coupling between the loss function and the metric we measure on?

>

What does a neural networks loss surface actually look like? Would be great to have visualisations of this... The distribution of fixed points, a vector field of stability, ?

Existence and density of sharp minimizers of the loss surface.

## Wish list

What do we care about in practice?

* The ability to train on large batches and get good generalisation
* ?

## Conclusions

?
